{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'autosklearn'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-3ef622fa136e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mpathlib\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mPath\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mautosklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclassification\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'autosklearn'"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\n",
    "#from sklearn.experimental import enable_hist_gradient_boosting\n",
    "#from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "from joblib import dump, load\n",
    "from sklearn.naive_bayes import GaussianNB \n",
    "from VisionUtils import *\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "import pandas as pd\n",
    "from mtcnn.mtcnn import MTCNN\n",
    "from pathlib import Path\n",
    "from sklearn.utils import shuffle\n",
    "import autosklearn.classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'xargs' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "!curl https://raw.githubusercontent.com/automl/auto-sklearn/master/requirements.txt | xargs -n 1 -L 1 pip install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trans(feat1, feat2):\n",
    "    f1 = [feat1[i1].reshape(-1,1) for i1 in range(len(feat1))]\n",
    "    f2 = [feat2[i2].reshape(-1,1) for i2 in range(len(feat2))]\n",
    "    cos_d = np.array([feat_distance_cosine_scalar(f1[i].T, f2[i]) for i in range(len(feat1))])\n",
    "    cos_d = cos_d.reshape(-1,1)\n",
    "    sqr_diff = np.power(np.abs(feat1- feat2), 2)\n",
    "    rat = feat1/feat2\n",
    "    data = np.hstack([cos_d, sqr_diff, rat])\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_aug_feat1 = np.load(\"features/train_aug_feat12.npy\")\n",
    "train_aug_feat2 = np.load(\"features/train_aug_feat22.npy\")\n",
    "train_aug_labels = np.load(\"features/train_aug_labels2.npy\")\n",
    "\n",
    "train_parallel_feat1 = np.load(\"features/train_parallel_feat11.npy\")\n",
    "train_parallel_feat2 = np.load(\"features/train_parallel_feat21.npy\")\n",
    "train_parallel_labels = np.load(\"features/train_parallel_labels.npy\")\n",
    "\n",
    "train_spotlight_feat1 = np.load(\"features/train_spotlight_feat11.npy\")\n",
    "train_spotlight_feat2 = np.load(\"features/train_spotlight_feat21.npy\")\n",
    "train_spotlight_labels = np.load(\"features/train_spotlight_labels.npy\")\n",
    "\n",
    "train_o_feat1 = np.load(\"features/train_feat1.npy\")\n",
    "train_o_feat2 = np.load(\"features/train_feat2.npy\")\n",
    "train_labels = np.load(\"features/train_labels.npy\")\n",
    "\n",
    "test_feat1 = np.load(\"features/test_feat1.npy\")\n",
    "test_feat2 = np.load(\"features/test_feat2.npy\")\n",
    "test_labels = np.load(\"features/test_labels.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels =  list(train_aug_labels) + list(train_spotlight_labels) +list(train_parallel_labels) \n",
    "\n",
    "labels = labels + list(train_labels) + list(train_labels) + list(train_labels) \n",
    "labels = labels + list(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_feat1 = np.vstack([train_aug_feat1, train_spotlight_feat1, train_parallel_feat1, \n",
    "                         train_o_feat1, train_o_feat1, train_o_feat1])\n",
    "train_feat2 = np.vstack([train_aug_feat2, train_spotlight_feat2, train_parallel_feat2, \n",
    "                         train_o_feat2, train_o_feat2, train_o_feat2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(246912, 128)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_feat2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(246912, 128)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_feat1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain = trans(train_feat1, train_feat2)\n",
    "xtest = trans(test_feat1, test_feat2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_len = len(xtrain)\n",
    "tst_len = len(xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.vstack([xtrain, xtest])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(259801, 257)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape\n",
    "#labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "259801"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "scaled_data = scaler.fit_transform(data)\n",
    "f_selector = SelectKBest(chi2, k = int(0.8*(len(data.T))))\n",
    "data_ = f_selector.fit_transform(scaled_data, labels )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "data_df = pd.DataFrame(data_)\n",
    "image_paths_csv = pd.read_csv(\"features/image_paths.csv\", index_col = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "all_data_df = pd.concat([image_paths_csv,data_df], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "len(all_data_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "xtrain, xtest, ytrain, ytest = train_test_split(all_data_df, labels, shuffle = True, random_state = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "paths_dict = {\n",
    "    \"train_paths1\": xtrain[\"path1\"],\n",
    "    \"train_paths2\": xtrain[\"path2\"],\n",
    "    \"test_paths1\": xtest[\"path1\"],\n",
    "    \"test_paths2\": xtest[\"path2\"]\n",
    "}\n",
    "xtrain1 = xtrain.drop([\"path1\", \"path2\", \"Unnamed: 0\"], axis = 1).values\n",
    "xtest1 = xtest.drop([\"path1\", \"path2\", \"Unnamed: 0\"], axis = 1).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain, xtest = data_[:tr_len], data_[-tst_len:]\n",
    "ytrain, ytest = labels[:tr_len], labels[-tst_len:]\n",
    "xtrain, ytrain = shuffle(xtrain, ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(246912, 205)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xtrain.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12889, 205)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xtest.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gradient Boosting Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import BaggingClassifier, VotingClassifier, GradientBoostingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "params_grid = {\n",
    "    \"loss\" : [\"deviance\", \"exponential\"],\n",
    "    \"n_estimators\": [10, 50,100, 150, 200],\n",
    "              }\n",
    "gboost = GradientBoostingClassifier()\n",
    "gs = GridSearchCV(gboost, param_grid = params_grid, cv = 5 )\n",
    "gs.fit(xtrain, ytrain)\n",
    "report(gs.cv_results_)\n",
    "gboost = gs.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "gboost = GradientBoostingClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_grid = {\n",
    "    \"loss\" : [\"deviance\", \"exponential\"],\n",
    "    \"n_estimators\": [10, 50,100, 150, 200],}\n",
    "\n",
    "gs = GridSearchCV(gboost, param_grid = params_grid, cv = 5 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs.fit(xtrain, ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gboost = gs.best_estimator_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
       "              learning_rate=0.1, loss='deviance', max_depth=3,\n",
       "              max_features=None, max_leaf_nodes=None,\n",
       "              min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "              min_samples_leaf=1, min_samples_split=2,\n",
       "              min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "              n_iter_no_change=None, presort='auto', random_state=None,\n",
       "              subsample=1.0, tol=0.0001, validation_fraction=0.1,\n",
       "              verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gboost.fit( xtrain, ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = gboost.predict(xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-The Accuracy of the the cllasifier: 0.8836216929164403\n",
      "-The recall Score:  0.8462128181539406\n",
      "-The precision score:  0.9173869680851063\n",
      "-The F1_score:  0.8803636943691179\n",
      "-The confusion matrix:\n",
      "[[5870  497]\n",
      " [1003 5519]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix, recall_score, precision_score, f1_score \n",
    "acc = accuracy_score(ytest,pred)\n",
    "conf = confusion_matrix(ytest, pred)\n",
    "rs = recall_score(ytest, pred)\n",
    "ps = precision_score(ytest, pred)\n",
    "f1 = f1_score(ytest, pred)\n",
    "print(\"-The Accuracy of the the cllasifier:\",acc)\n",
    "print(\"-The recall Score: \", rs)\n",
    "print(\"-The precision score: \", ps)\n",
    "print(\"-The F1_score: \", f1)\n",
    "print(\"-The confusion matrix:\" )\n",
    "print(conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "false_positive = []\n",
    "false_positive_pred = []\n",
    "\n",
    "false_negative = []\n",
    "false_negative_pred = []\n",
    "\n",
    "for i in range(len(pred)):\n",
    "    ### False Positive check\n",
    "    if ((pred[i]==1) & (ytest[i] ==0)):\n",
    "        false_positive.append(i)\n",
    "        false_positive_pred.append(pred[i])\n",
    "    ### False Negative check\n",
    "    elif ((pred[i] == 0) &(ytest[i]==1)):\n",
    "        false_negative.append(i)\n",
    "        false_negative_pred.append(pred[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "285\n",
      "452\n"
     ]
    }
   ],
   "source": [
    "print(len(false_positive))\n",
    "print(len(false_negative))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "False Positves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'paths_dict' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-33-71eb2c629a11>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mfalse_image_lst1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpaths_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"test_paths1\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfalse_positive\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mfalse_image_lst2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpaths_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"test_paths2\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfalse_positive\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'paths_dict' is not defined"
     ]
    }
   ],
   "source": [
    "false_image_lst1 = list(np.array(paths_dict[\"test_paths1\"])[false_positive])\n",
    "false_image_lst2 = list(np.array(paths_dict[\"test_paths2\"])[false_positive])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "def showfalse(idx, i):\n",
    "    \n",
    "    try:\n",
    "        imgs = [ plt.imread(\"data/images/\" + false_image_lst1[idx]), \n",
    "               plt.imread(\"data/images/\" + false_image_lst2[idx])]\n",
    "        pathls = [\"#: {} data/images/\".format(i) + false_image_lst1[idx], \n",
    "                  \"#: {} data/images/\".format(i) + false_image_lst2[idx]]\n",
    "        for i in range(len(imgs)):\n",
    "            bb = detect_faces(imgs[i], m)\n",
    "            ax = show_img(imgs[i])\n",
    "            \n",
    "            for b in bb:\n",
    "                write_txt(ax, (b[0], b[1]),pathls[i], 14)\n",
    "                draw_bb(ax, b)\n",
    "            write_txt(ax, (0, 0),\"{}\".format(i), 20)\n",
    "        #print(50*\"#\")\n",
    "    except FileNotFoundError:\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "os.path.exists(\"data/images/\" + false_image_lst1[1]) \n",
    "os.path.exists(\"data/images/\" + false_image_lst1[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['demo/PipelineParts/feature_selector.joblib']"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dump(gboost, \"demo/PipelineParts/GboostModel.joblib\")\n",
    "dump(scaler, \"demo/PipelineParts/scaler.joblib\")\n",
    "dump(f_selector, \"demo/PipelineParts/feature_selector.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vision1",
   "language": "python",
   "name": "vision1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
