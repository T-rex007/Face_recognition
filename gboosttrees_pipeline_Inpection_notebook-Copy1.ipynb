{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\n",
    "#from sklearn.experimental import enable_hist_gradient_boosting\n",
    "#from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "from joblib import dump, load\n",
    "from sklearn.naive_bayes import GaussianNB \n",
    "from VisionUtils import *\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "import pandas as pd\n",
    "from mtcnn.mtcnn import MTCNN\n",
    "from pathlib import Path\n",
    "from sklearn.utils import shuffle\n",
    "from tqdm import tqdm\n",
    "#import autosklearn.classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### !curl https://raw.githubusercontent.com/automl/auto-sklearn/master/requirements.txt | xargs -n 1 -L 1 pip install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trans(feat1, feat2):\n",
    "    f1 = [feat1[i1].reshape(-1,1) for i1 in range(len(feat1))]\n",
    "    f2 = [feat2[i2].reshape(-1,1) for i2 in range(len(feat2))]\n",
    "    cos_d = np.array([feat_distance_cosine_scalar(f1[i].T, f2[i]) for i in range(len(feat1))])\n",
    "    cos_d = cos_d.reshape(-1,1)\n",
    "    sqr_diff = np.power(np.abs(feat1- feat2), 2)\n",
    "    rat = feat1/feat2\n",
    "    data = np.hstack([cos_d, sqr_diff, rat])\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train_aug_feat1 = np.load(\"features/train_aug_feat12.npy\")\n",
    "train_aug_feat2 = np.load(\"features/train_aug_feat22.npy\")\n",
    "train_aug_labels = np.load(\"features/train_aug_labels2.npy\")\n",
    "\n",
    "train_parallel_feat1 = np.load(\"features/train_parallel_feat11.npy\")\n",
    "train_parallel_feat2 = np.load(\"features/train_parallel_feat21.npy\")\n",
    "train_parallel_labels = np.load(\"features/train_parallel_labels.npy\")\n",
    "\n",
    "train_spotlight_feat1 = np.load(\"features/train_spotlight_feat11.npy\")\n",
    "train_spotlight_feat2 = np.load(\"features/train_spotlight_feat21.npy\")\n",
    "train_spotlight_labels = np.load(\"features/train_spotlight_labels.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_feat1 = np.load(\"features2/train_feat1.npy\")\n",
    "train_feat2 = np.load(\"features2/train_feat2.npy\")\n",
    "train_labels = np.load(\"features2/train_labels.npy\")\n",
    "\n",
    "test_feat1 = np.load(\"features2/test_feat1.npy\")\n",
    "test_feat2 = np.load(\"features2/test_feat2.npy\")\n",
    "test_labels = np.load(\"features2/test_labels.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = list(train_labels) + list(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "473600"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain = trans(train_feat1, train_feat2)\n",
    "xtest = trans(test_feat1, test_feat2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_len = len(xtrain)\n",
    "tst_len = len(xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.vstack([xtrain, xtest])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.4152974 , -0.4509149 , -0.15066573, ..., -1.0045165 ,\n",
       "         0.26249442,  2.1781526 ],\n",
       "       [-0.46679398, -0.01878167, -0.7963252 , ...,  0.59322894,\n",
       "         0.25759584,  1.4256115 ],\n",
       "       [-0.7544749 , -0.15702224, -0.6228995 , ..., -0.40557706,\n",
       "         0.35926935,  0.22421257],\n",
       "       ...,\n",
       "       [-0.24145341, -0.64844954,  0.34552258, ..., -0.11110175,\n",
       "         1.4846197 ,  0.5854943 ],\n",
       "       [-1.2245702 , -1.246251  , -0.60789293, ...,  0.07093086,\n",
       "         0.3926579 , -0.0261232 ],\n",
       "       [-1.6080754 , -0.6366339 , -0.48899055, ..., -1.1670861 ,\n",
       "         1.8307773 ,  0.98391616]], dtype=float32)"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_feat1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(355200, 128)"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_feat1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(355200, 128)"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_feat2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(118400, 128)"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_feat1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(118400, 128)"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_feat2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(473600, 257)"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape\n",
    "#labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "473600"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "scaled_data = scaler.fit_transform(data)\n",
    "f_selector = SelectKBest(chi2, k = int(0.8*(len(data.T))))\n",
    "data_ = f_selector.fit_transform(scaled_data, labels )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "data_df = pd.DataFrame(data_)\n",
    "image_paths_csv = pd.read_csv(\"features/image_paths.csv\", index_col = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "all_data_df = pd.concat([image_paths_csv,data_df], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "len(all_data_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "xtrain, xtest, ytrain, ytest = train_test_split(all_data_df, labels, shuffle = True, random_state = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "paths_dict = {\n",
    "    \"train_paths1\": xtrain[\"path1\"],\n",
    "    \"train_paths2\": xtrain[\"path2\"],\n",
    "    \"test_paths1\": xtest[\"path1\"],\n",
    "    \"test_paths2\": xtest[\"path2\"]\n",
    "}\n",
    "xtrain1 = xtrain.drop([\"path1\", \"path2\", \"Unnamed: 0\"], axis = 1).values\n",
    "xtest1 = xtest.drop([\"path1\", \"path2\", \"Unnamed: 0\"], axis = 1).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain, xtest = data_[:tr_len], data_[-tst_len:]\n",
    "ytrain, ytest = labels[:tr_len], labels[-tst_len:]\n",
    "xtrain, ytrain = shuffle(xtrain, ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(355200, 205)"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xtrain.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(118400, 205)"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xtest.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gradient Boosting Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import BaggingClassifier, VotingClassifier, GradientBoostingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "params_grid = {\n",
    "    \"loss\" : [\"deviance\", \"exponential\"],\n",
    "    \"n_estimators\": [10, 50,100, 150, 200],\n",
    "              }\n",
    "gboost = GradientBoostingClassifier()\n",
    "gs = GridSearchCV(gboost, param_grid = params_grid, cv = 5 )\n",
    "gs.fit(xtrain, ytrain)\n",
    "report(gs.cv_results_)\n",
    "gboost = gs.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "gboost = GradientBoostingClassifier()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "params_grid = {\n",
    "    \"loss\" : [\"deviance\", \"exponential\"],\n",
    "    \"n_estimators\": [10, 50,100, 150, 200],}\n",
    "\n",
    "gs = GridSearchCV(gboost, param_grid = params_grid, cv = 5 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
       "              learning_rate=0.1, loss='deviance', max_depth=3,\n",
       "              max_features=None, max_leaf_nodes=None,\n",
       "              min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "              min_samples_leaf=1, min_samples_split=2,\n",
       "              min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "              n_iter_no_change=None, presort='auto', random_state=None,\n",
       "              subsample=1.0, tol=0.0001, validation_fraction=0.1,\n",
       "              verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gboost.fit(xtrain, ytrain)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "gboost = gs.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gboost.fit( xtrain, ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = gboost.predict(xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-The Accuracy of the the cllasifier: 0.8774155405405405\n",
      "-The recall Score:  0.8422031691272217\n",
      "-The precision score:  0.9057379285259616\n",
      "-The F1_score:  0.8728158572705446\n",
      "-The confusion matrix:\n",
      "[[54084  5183]\n",
      " [ 9331 49802]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix, recall_score, precision_score, f1_score \n",
    "acc = accuracy_score(ytest,pred)\n",
    "conf = confusion_matrix(ytest, pred)\n",
    "rs = recall_score(ytest, pred)\n",
    "ps = precision_score(ytest, pred)\n",
    "f1 = f1_score(ytest, pred)\n",
    "print(\"-The Accuracy of the the cllasifier:\",acc)\n",
    "print(\"-The recall Score: \", rs)\n",
    "print(\"-The precision score: \", ps)\n",
    "print(\"-The F1_score: \", f1)\n",
    "print(\"-The confusion matrix:\" )\n",
    "print(conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "false_positive = []\n",
    "false_positive_pred = []\n",
    "\n",
    "false_negative = []\n",
    "false_negative_pred = []\n",
    "\n",
    "for i in range(len(pred)):\n",
    "    ### False Positive check\n",
    "    if ((pred[i]==1) & (ytest[i] ==0)):\n",
    "        false_positive.append(i)\n",
    "        false_positive_pred.append(pred[i])\n",
    "    ### False Negative check\n",
    "    elif ((pred[i] == 0) &(ytest[i]==1)):\n",
    "        false_negative.append(i)\n",
    "        false_negative_pred.append(pred[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5183\n",
      "9331\n"
     ]
    }
   ],
   "source": [
    "print(len(false_positive))\n",
    "print(len(false_negative))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "False Positves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'paths_dict' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-202-71eb2c629a11>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mfalse_image_lst1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpaths_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"test_paths1\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfalse_positive\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mfalse_image_lst2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpaths_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"test_paths2\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfalse_positive\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'paths_dict' is not defined"
     ]
    }
   ],
   "source": [
    "false_image_lst1 = list(np.array(paths_dict[\"test_paths1\"])[false_positive])\n",
    "false_image_lst2 = list(np.array(paths_dict[\"test_paths2\"])[false_positive])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "def showfalse(idx, i):\n",
    "    \n",
    "    try:\n",
    "        imgs = [ plt.imread(\"data/images/\" + false_image_lst1[idx]), \n",
    "               plt.imread(\"data/images/\" + false_image_lst2[idx])]\n",
    "        pathls = [\"#: {} data/images/\".format(i) + false_image_lst1[idx], \n",
    "                  \"#: {} data/images/\".format(i) + false_image_lst2[idx]]\n",
    "        for i in range(len(imgs)):\n",
    "            bb = detect_faces(imgs[i], m)\n",
    "            ax = show_img(imgs[i])\n",
    "            \n",
    "            for b in bb:\n",
    "                write_txt(ax, (b[0], b[1]),pathls[i], 14)\n",
    "                draw_bb(ax, b)\n",
    "            write_txt(ax, (0, 0),\"{}\".format(i), 20)\n",
    "        #print(50*\"#\")\n",
    "    except FileNotFoundError:\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['demo/PipelineParts/feature_selector.joblib']"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dump(gboost, \"demo/PipelineParts/GboostModel.joblib\")\n",
    "dump(scaler, \"demo/PipelineParts/scaler.joblib\")\n",
    "dump(f_selector, \"demo/PipelineParts/feature_selector.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
       "              learning_rate=0.1, loss='deviance', max_depth=3,\n",
       "              max_features=None, max_leaf_nodes=None,\n",
       "              min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "              min_samples_leaf=1, min_samples_split=2,\n",
       "              min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "              n_iter_no_change=None, presort='auto', random_state=None,\n",
       "              subsample=1.0, tol=0.0001, validation_fraction=0.1,\n",
       "              verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "gboost = load(\"demo/PipelineParts/GboostModel.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = gboost.predict(xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-The Accuracy of the the cllasifier: 0.8774155405405405\n",
      "-The recall Score:  0.8422031691272217\n",
      "-The precision score:  0.9057379285259616\n",
      "-The F1_score:  0.8728158572705446\n",
      "-The confusion matrix:\n",
      "[[54084  5183]\n",
      " [ 9331 49802]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix, recall_score, precision_score, f1_score \n",
    "acc = accuracy_score(ytest,pred)\n",
    "conf = confusion_matrix(ytest, pred)\n",
    "rs = recall_score(ytest, pred)\n",
    "ps = precision_score(ytest, pred)\n",
    "f1 = f1_score(ytest, pred)\n",
    "print(\"-The Accuracy of the the cllasifier:\",acc)\n",
    "print(\"-The recall Score: \", rs)\n",
    "print(\"-The precision score: \", ps)\n",
    "print(\"-The F1_score: \", f1)\n",
    "print(\"-The confusion matrix:\" )\n",
    "print(conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vision1",
   "language": "python",
   "name": "vision1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
