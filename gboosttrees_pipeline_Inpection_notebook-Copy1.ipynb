{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "#from sklearn.svm import SVC, LinearSVC\n",
    "#from sklearn.linear_model import SGDClassifier\n",
    "#from sklearn.tree import DecisionTreeClassifier\n",
    "#from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\n",
    "#from sklearn.experimental import enable_hist_gradient_boosting\n",
    "#from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "from joblib import dump, load\n",
    "#from sklearn.naive_bayes import GaussianNB \n",
    "from VisionUtils import *\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "import pandas as pd\n",
    "from mtcnn.mtcnn import MTCNN\n",
    "from pathlib import Path\n",
    "from sklearn.utils import shuffle\n",
    "from tqdm import tqdm\n",
    "#import autosklearn.classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### !curl https://raw.githubusercontent.com/automl/auto-sklearn/master/requirements.txt | xargs -n 1 -L 1 pip install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trans(feat1, feat2):\n",
    "    f1 = [feat1[i1].reshape(-1,1) for i1 in range(len(feat1))]\n",
    "    f2 = [feat2[i2].reshape(-1,1) for i2 in range(len(feat2))]\n",
    "    cos_d = np.array([feat_distance_cosine_scalar(f1[i].T, f2[i]) for i in range(len(feat1))])\n",
    "    cos_d = cos_d.reshape(-1,1)\n",
    "    sqr_diff = np.power(np.abs(feat1- feat2), 2)\n",
    "    rat = feat1/feat2\n",
    "    data = np.hstack([cos_d, sqr_diff, rat])\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train_aug_feat1 = np.load(\"features/train_aug_feat12.npy\")\n",
    "train_aug_feat2 = np.load(\"features/train_aug_feat22.npy\")\n",
    "train_aug_labels = np.load(\"features/train_aug_labels2.npy\")\n",
    "\n",
    "train_parallel_feat1 = np.load(\"features/train_parallel_feat11.npy\")\n",
    "train_parallel_feat2 = np.load(\"features/train_parallel_feat21.npy\")\n",
    "train_parallel_labels = np.load(\"features/train_parallel_labels.npy\")\n",
    "\n",
    "train_spotlight_feat1 = np.load(\"features/train_spotlight_feat11.npy\")\n",
    "train_spotlight_feat2 = np.load(\"features/train_spotlight_feat21.npy\")\n",
    "train_spotlight_labels = np.load(\"features/train_spotlight_labels.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_feat1_o = np.load(\"features/train_feat1.npy\")\n",
    "train_feat2_o = np.load(\"features/train_feat2.npy\")\n",
    "train_labels_o = np.load(\"features/train_labels.npy\")\n",
    "\n",
    "train_feat1_aug = np.load(\"features3/train_feat1.npy\")\n",
    "train_feat2_aug = np.load(\"features3/train_feat2.npy\")\n",
    "train_labels_aug = np.load(\"features3/train_labels.npy\")\n",
    "\n",
    "train_feat1_mb = np.load(\"features_motion_blur/train_feat1.npy\")\n",
    "train_feat2_mb = np.load(\"features_motion_blur/train_feat2.npy\")\n",
    "train_labels_mb = np.load(\"features_motion_blur/train_labels.npy\")\n",
    "\n",
    "train_feat1_som = np.load(\"features2/train_feat1.npy\")\n",
    "train_feat2_som = np.load(\"features2/train_feat2.npy\")\n",
    "train_labels_som = np.load(\"features2/train_labels.npy\")\n",
    "\n",
    "#test_feat1 = np.load(\"features/test_feat1.npy\")\n",
    "#test_feat2 = np.load(\"features/test_feat2.npy\")\n",
    "#test_labels = np.load(\"features/test_labels.npy\")\n",
    "\n",
    "#test_feat1 = np.load(\"features2/test_feat1.npy\")\n",
    "#test_feat2 = np.load(\"features2/test_feat2.npy\")\n",
    "#test_labels = np.load(\"features2/test_labels.npy\")\n",
    "\n",
    "test_feat1 = np.load(\"features/test_feat1.npy\")\n",
    "test_feat2 = np.load(\"features/test_feat2.npy\")\n",
    "test_labels = np.load(\"features/test_labels.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = list(train_labels_o) + list(train_labels_aug) + list(train_labels_mb)+ list(train_labels_som) + list(test_labels) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "651092"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "651092"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_feat1 = np.vstack([train_feat1_o, train_feat1_aug, train_feat1_mb, train_feat1_som])\n",
    "train_feat2 = np.vstack([train_feat2_o, train_feat2_aug, train_feat2_mb, train_feat2_som])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(634937, 128)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_feat1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16155, 128)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_feat1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16155, 128)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_feat2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain = trans(train_feat1, train_feat2)\n",
    "xtest = trans(test_feat1, test_feat2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_len = len(xtrain)\n",
    "tst_len = len(xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.vstack([xtrain, xtest])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.04792953,  0.7563431 , -0.84855455, ..., -0.22007652,\n",
       "        -0.274067  ,  0.25541857],\n",
       "       [ 2.084942  , -0.3050092 , -1.309191  , ...,  0.5104576 ,\n",
       "         1.4823234 ,  1.0534424 ],\n",
       "       [-0.28587088, -0.43783346, -0.6955893 , ...,  0.9054784 ,\n",
       "         0.47151074, -0.8195881 ],\n",
       "       ...,\n",
       "       [-0.14162165,  0.566401  , -0.29851282, ..., -0.9206232 ,\n",
       "         0.07092834,  0.22003533],\n",
       "       [ 1.8893486 ,  0.30587184,  0.5176531 , ...,  0.7488258 ,\n",
       "         0.22750878, -1.5933679 ],\n",
       "       [-0.0756229 , -0.5898951 , -0.41407582, ..., -0.9840678 ,\n",
       "         0.84356314,  0.14764242]], dtype=float32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_feat1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(634937, 128)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_feat1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(634937, 128)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_feat2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16155, 128)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_feat1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16155, 128)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_feat2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(651092, 257)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape\n",
    "#labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "651092"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "scaled_data = scaler.fit_transform(data)\n",
    "f_selector = SelectKBest(chi2, k = int(0.8*(len(data.T))))\n",
    "data_ = f_selector.fit_transform(scaled_data, labels )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "data_df = pd.DataFrame(data_)\n",
    "image_paths_csv = pd.read_csv(\"features/image_paths.csv\", index_col = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "all_data_df = pd.concat([image_paths_csv,data_df], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "len(all_data_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "xtrain, xtest, ytrain, ytest = train_test_split(all_data_df, labels, shuffle = True, random_state = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "paths_dict = {\n",
    "    \"train_paths1\": xtrain[\"path1\"],\n",
    "    \"train_paths2\": xtrain[\"path2\"],\n",
    "    \"test_paths1\": xtest[\"path1\"],\n",
    "    \"test_paths2\": xtest[\"path2\"]\n",
    "}\n",
    "xtrain1 = xtrain.drop([\"path1\", \"path2\", \"Unnamed: 0\"], axis = 1).values\n",
    "xtest1 = xtest.drop([\"path1\", \"path2\", \"Unnamed: 0\"], axis = 1).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain, xtest = data_[:tr_len], data_[-tst_len:]\n",
    "ytrain, ytest = labels[:tr_len], labels[-tst_len:]\n",
    "xtrain, ytrain = shuffle(xtrain, ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(634937, 205)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xtrain.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16155, 205)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xtest.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gradient Boosting Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import BaggingClassifier, VotingClassifier, GradientBoostingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "params_grid = {\n",
    "    \"loss\" : [\"exponential\"],\n",
    "    \"n_estimators\": [60,70,90], \"max_depth\": 10\n",
    "              }\n",
    "gboost = GradientBoostingClassifier()\n",
    "gs = GridSearchCV(gboost, param_grid = params_grid, cv = 2 )\n",
    "gs.fit(xtrain, ytrain)\n",
    "report(gs.cv_results_)\n",
    "gboost = gs.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "gboost = GradientBoostingClassifier(loss='exponential', n_estimators=60, max_depth=6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "params_grid = {\n",
    "    \"loss\" : [\"deviance\", \"exponential\"],\n",
    "    \"n_estimators\": [10, 50,100, 150, 200],}\n",
    "\n",
    "gs = GridSearchCV(gboost, param_grid = params_grid, cv = 5 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "gboost.fit(xtrain, ytrain)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "gboost = gs.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
       "              learning_rate=0.1, loss='exponential', max_depth=6,\n",
       "              max_features=None, max_leaf_nodes=None,\n",
       "              min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "              min_samples_leaf=1, min_samples_split=2,\n",
       "              min_weight_fraction_leaf=0.0, n_estimators=60,\n",
       "              n_iter_no_change=None, presort='auto', random_state=None,\n",
       "              subsample=1.0, tol=0.0001, validation_fraction=0.1,\n",
       "              verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gboost.fit( xtrain, ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = gboost.predict(xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-The Accuracy of the the cllasifier: 0.8886412875270814\n",
      "-The recall Score:  0.855923818946327\n",
      "-The precision score:  0.9160820648577102\n",
      "-The F1_score:  0.8849817786586536\n",
      "-The confusion matrix:\n",
      "[[7435  634]\n",
      " [1165 6921]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix, recall_score, precision_score, f1_score \n",
    "acc = accuracy_score(ytest,pred)\n",
    "conf = confusion_matrix(ytest, pred)\n",
    "rs = recall_score(ytest, pred)\n",
    "ps = precision_score(ytest, pred)\n",
    "f1 = f1_score(ytest, pred)\n",
    "print(\"-The Accuracy of the the cllasifier:\",acc)\n",
    "print(\"-The recall Score: \", rs)\n",
    "print(\"-The precision score: \", ps)\n",
    "print(\"-The F1_score: \", f1)\n",
    "print(\"-The confusion matrix:\" )\n",
    "print(conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-The Accuracy of the the cllasifier: 0.7332710280373832\n",
      "-The recall Score:  0.7061419639573373\n",
      "-The precision score:  0.7535321821036107\n",
      "-The F1_score:  0.7290677805202203\n",
      "-The confusion matrix:\n",
      "[[2003  628]\n",
      " [ 799 1920]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix, recall_score, precision_score, f1_score \n",
    "acc = accuracy_score(ytest,pred)\n",
    "conf = confusion_matrix(ytest, pred)\n",
    "rs = recall_score(ytest, pred)\n",
    "ps = precision_score(ytest, pred)\n",
    "f1 = f1_score(ytest, pred)\n",
    "print(\"-The Accuracy of the the cllasifier:\",acc)\n",
    "print(\"-The recall Score: \", rs)\n",
    "print(\"-The precision score: \", ps)\n",
    "print(\"-The F1_score: \", f1)\n",
    "print(\"-The confusion matrix:\" )\n",
    "print(conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "false_positive = []\n",
    "false_positive_pred = []\n",
    "\n",
    "false_negative = []\n",
    "false_negative_pred = []\n",
    "\n",
    "for i in range(len(pred)):\n",
    "    ### False Positive check\n",
    "    if ((pred[i]==1) & (ytest[i] ==0)):\n",
    "        false_positive.append(i)\n",
    "        false_positive_pred.append(pred[i])\n",
    "    ### False Negative check\n",
    "    elif ((pred[i] == 0) &(ytest[i]==1)):\n",
    "        false_negative.append(i)\n",
    "        false_negative_pred.append(pred[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7741\n",
      "14150\n"
     ]
    }
   ],
   "source": [
    "print(len(false_positive))\n",
    "print(len(false_negative))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "False Positves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'paths_dict' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-235-71eb2c629a11>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mfalse_image_lst1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpaths_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"test_paths1\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfalse_positive\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mfalse_image_lst2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpaths_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"test_paths2\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfalse_positive\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'paths_dict' is not defined"
     ]
    }
   ],
   "source": [
    "false_image_lst1 = list(np.array(paths_dict[\"test_paths1\"])[false_positive])\n",
    "false_image_lst2 = list(np.array(paths_dict[\"test_paths2\"])[false_positive])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "def showfalse(idx, i):\n",
    "    \n",
    "    try:\n",
    "        imgs = [ plt.imread(\"data/images/\" + false_image_lst1[idx]), \n",
    "               plt.imread(\"data/images/\" + false_image_lst2[idx])]\n",
    "        pathls = [\"#: {} data/images/\".format(i) + false_image_lst1[idx], \n",
    "                  \"#: {} data/images/\".format(i) + false_image_lst2[idx]]\n",
    "        for i in range(len(imgs)):\n",
    "            bb = detect_faces(imgs[i], m)\n",
    "            ax = show_img(imgs[i])\n",
    "            \n",
    "            for b in bb:\n",
    "                write_txt(ax, (b[0], b[1]),pathls[i], 14)\n",
    "                draw_bb(ax, b)\n",
    "            write_txt(ax, (0, 0),\"{}\".format(i), 20)\n",
    "        #print(50*\"#\")\n",
    "    except FileNotFoundError:\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['demo/PipelineParts/feature_selector.joblib']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dump(gboost, \"demo/PipelineParts/GboostModel.joblib\")\n",
    "dump(scaler, \"demo/PipelineParts/scaler.joblib\")\n",
    "dump(f_selector, \"demo/PipelineParts/feature_selector.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
       "              learning_rate=0.1, loss='exponential', max_depth=6,\n",
       "              max_features=None, max_leaf_nodes=None,\n",
       "              min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "              min_samples_leaf=1, min_samples_split=2,\n",
       "              min_weight_fraction_leaf=0.0, n_estimators=60,\n",
       "              n_iter_no_change=None, presort='auto', random_state=None,\n",
       "              subsample=1.0, tol=0.0001, validation_fraction=0.1,\n",
       "              verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "gboost = load(\"demo/PipelineParts/GboostModel.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = gboost.predict(xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-The Accuracy of the the cllasifier: 0.8774155405405405\n",
      "-The recall Score:  0.8422031691272217\n",
      "-The precision score:  0.9057379285259616\n",
      "-The F1_score:  0.8728158572705446\n",
      "-The confusion matrix:\n",
      "[[54084  5183]\n",
      " [ 9331 49802]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix, recall_score, precision_score, f1_score \n",
    "acc = accuracy_score(ytest,pred)\n",
    "conf = confusion_matrix(ytest, pred)\n",
    "rs = recall_score(ytest, pred)\n",
    "ps = precision_score(ytest, pred)\n",
    "f1 = f1_score(ytest, pred)\n",
    "print(\"-The Accuracy of the the cllasifier:\",acc)\n",
    "print(\"-The recall Score: \", rs)\n",
    "print(\"-The precision score: \", ps)\n",
    "print(\"-The F1_score: \", f1)\n",
    "print(\"-The confusion matrix:\" )\n",
    "print(conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vision1",
   "language": "python",
   "name": "vision1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
